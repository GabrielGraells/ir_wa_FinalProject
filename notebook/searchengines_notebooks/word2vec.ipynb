{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word2vec.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPKjpja7iV70iTz99BXi4kg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"5YFB3CCr6XMK"},"source":["# Word2Vec + Cosine Similarity\n","\n","Our choosed method to rank is the combination of word2vec and cosine similarity. We have followed the implementation suggested in this [paper](\n","https://arxiv.org/pdf/1507.07998.pdf), *Document Embedding with Paragraph Vectors*.\n","\n","The ranking works as follows. First we create a vocabulary from our collection using Word2Vec class in gensim.models. For each term in each document we transform it using Word2Vec embedding. Then for each document we average the resulting vector in to one single vector representative of the model. \n","\n","After doing this for the entire collection we obtain the vector representation of teach document. In query time we repeat the exact same process. Transform each term in query into its corresponding word2vec embedding and average all vector to obtain a final one representative of the query. \n","\n","For ranking we use cosine similarity between each query and doc. Top N documents are returned.\n","\n","https://www.analyticsvidhya.com/blog/2020/08/information-retrieval-using-word2vec-based-vector-space-model/\n","\n","https://arxiv.org/pdf/1507.07998.pdf"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G-HWMAny2dxh","executionInfo":{"status":"ok","timestamp":1607282766361,"user_tz":-60,"elapsed":31561,"user":{"displayName":"GABRIEL GRAELLS","photoUrl":"","userId":"06318594296163771906"}},"outputId":"220ea43b-2158-4054-bd74-6e0656b9b0ba"},"source":["import pandas as pd\n","import re\n","import spacy\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import pickle"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":191},"id":"KjUZFi_06jb5","executionInfo":{"status":"ok","timestamp":1607284419022,"user_tz":-60,"elapsed":1130,"user":{"displayName":"GABRIEL GRAELLS","photoUrl":"","userId":"06318594296163771906"}},"outputId":"4d64fb48-392f-4933-8ee8-849dea44c6d5"},"source":["data_Final = pd.read_csv(f\"{PATH}final_Tweets.csv\")\n","data = data_Final.copy()\n","data_Final.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>created_at</th>\n","      <th>favorite_count</th>\n","      <th>full_text</th>\n","      <th>id</th>\n","      <th>retweet_count</th>\n","      <th>user.id</th>\n","      <th>user.name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2020-11-11</td>\n","      <td>4</td>\n","      <td>International friendly roundup: Finland stun F...</td>\n","      <td>1326667371730378753</td>\n","      <td>1</td>\n","      <td>16042794</td>\n","      <td>Guardian US</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2020-11-11</td>\n","      <td>11</td>\n","      <td>When Joe Biden formally takes over the preside...</td>\n","      <td>1326666012142526466</td>\n","      <td>5</td>\n","      <td>16042794</td>\n","      <td>Guardian US</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2020-11-11</td>\n","      <td>4</td>\n","      <td>New Yorker fires Jeffrey Toobin after he repor...</td>\n","      <td>1326663505454510081</td>\n","      <td>1</td>\n","      <td>16042794</td>\n","      <td>Guardian US</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2020-11-11</td>\n","      <td>8</td>\n","      <td>One week on: how has Donald Trump handled losi...</td>\n","      <td>1326661105498796032</td>\n","      <td>1</td>\n","      <td>16042794</td>\n","      <td>Guardian US</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>2020-11-11</td>\n","      <td>13</td>\n","      <td>France pays tribute to six-year-old resistance...</td>\n","      <td>1326659924278046728</td>\n","      <td>6</td>\n","      <td>16042794</td>\n","      <td>Guardian US</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0  created_at  favorite_count  ... retweet_count   user.id    user.name\n","0           0  2020-11-11               4  ...             1  16042794  Guardian US\n","1           1  2020-11-11              11  ...             5  16042794  Guardian US\n","2           2  2020-11-11               4  ...             1  16042794  Guardian US\n","3           3  2020-11-11               8  ...             1  16042794  Guardian US\n","4           4  2020-11-11              13  ...             6  16042794  Guardian US\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"iX-r0eab8N-0"},"source":["## Text Prepocessing\n","\n","* Lowercase the text\n","* Expand Contractions\n","* Clean the text\n","* Remove Stopwords\n","* Lemmatize words\n","\n","In this method we have decided to implement a stronger text processing to retain as much as possible relations and semantics between words."]},{"cell_type":"code","metadata":{"id":"Ba-ljl0V_Dtb"},"source":["def expand_contractions(text, contractions_dict, contractions_re):\n","    \"\"\"\n","    Given contraction find match and substitude\n","    \"\"\"\n","    def replace(match):\n","        return contractions_dict[match.group(0)]\n","    return contractions_re.sub(replace,text)\n","\n","def clean_text(text):\n","    \"\"\"\n","    * Remove words with digits\n","    * Replace newline characters with space\n","    * Remove URLS\n","    * Replace non english chars with space\n","    \"\"\"\n","    # Remove digits\n","    text=re.sub('\\w*\\d\\w*','', text)\n","\n","    # Remove new Line chars\n","    text=re.sub('\\n',' ',text)\n","\n","    #Remove links\n","    text=re.sub(r\"http\\S+\", \"\", text)\n","\n","    #Replace non-english chars\n","    text=re.sub('[^a-z]',' ',text)\n","    \n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xtPz07C68HZo"},"source":["def preprocessing(text):\n","    \"\"\"\n","    Given a pandas dataframe apply preprocessing techinques\n","        * Lowercase the text\n","        * Expand Contractions\n","        * Clean the text\n","        * Remove Stopwords\n","        * Lemmatize words\n","    \"\"\"\n","    # Lower case\n","    text = text.lower()\n","\n","    # Regular expression for finding contractions\n","    contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n","\n","    #Expand contractions\n","    text = expand_contractions(text,contractions_dict,contractions_re)\n","    text = clean_text(text)\n","\n","    #Remove added spaces\n","    text = re.sub(\" +\",\" \",text)\n","    text = text.strip()\n","\n","    #Stop words and Lemmatizing\n","    text = ' '.join([token.lemma_ for token in list(nlp(text)) if (token.is_stop==False)])\n","\n","    return text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fa9G4AFr-TBT"},"source":["# Dictionary of english Contractions\n","contractions_dict = { \"ain't\": \"are not\",\"'s\":\" is\",\"aren't\": \"are not\",\"can't\": \"can not\",\"can't've\": \"cannot have\",\n","\"'cause\": \"because\",\"could've\": \"could have\",\"couldn't\": \"could not\",\"couldn't've\": \"could not have\",\n","\"didn't\": \"did not\",\"doesn't\": \"does not\",\"don't\": \"do not\",\"hadn't\": \"had not\",\"hadn't've\": \"had not have\",\n","\"hasn't\": \"has not\",\"haven't\": \"have not\",\"he'd\": \"he would\",\"he'd've\": \"he would have\",\"he'll\": \"he will\",\n","\"he'll've\": \"he will have\",\"how'd\": \"how did\",\"how'd'y\": \"how do you\",\"how'll\": \"how will\",\"i'd\": \"i would\",\n","\"i'd've\": \"i would have\",\"i'll\": \"i will\",\"i'll've\": \"i will have\",\"i'm\": \"i am\",\"i've\": \"i have\",\n","\"isn't\": \"is not\",\"it'd\": \"it would\",\"it'd've\": \"it would have\",\"it'll\": \"it will\",\"it'll've\": \"it will have\",\n","\"let's\": \"let us\",\"ma'am\": \"madam\",\"mayn't\": \"may not\",\"might've\": \"might have\",\"mightn't\": \"might not\",\n","\"mightn't've\": \"might not have\",\"must've\": \"must have\",\"mustn't\": \"must not\",\"mustn't've\": \"must not have\",\n","\"needn't\": \"need not\",\"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\"oughtn't\": \"ought not\",\n","\"oughtn't've\": \"ought not have\",\"shan't\": \"shall not\",\"sha'n't\": \"shall not\",\n","\"shan't've\": \"shall not have\",\"she'd\": \"she would\",\"she'd've\": \"she would have\",\"she'll\": \"she will\",\n","\"she'll've\": \"she will have\",\"should've\": \"should have\",\"shouldn't\": \"should not\",\n","\"shouldn't've\": \"should not have\",\"so've\": \"so have\",\"that'd\": \"that would\",\"that'd've\": \"that would have\",\n","\"there'd\": \"there would\",\"there'd've\": \"there would have\",\n","\"they'd\": \"they would\",\"they'd've\": \"they would have\",\"they'll\": \"they will\",\"they'll've\": \"they will have\",\n","\"they're\": \"they are\",\"they've\": \"they have\",\"to've\": \"to have\",\"wasn't\": \"was not\",\"we'd\": \"we would\",\n","\"we'd've\": \"we would have\",\"we'll\": \"we will\",\"we'll've\": \"we will have\",\"we're\": \"we are\",\"we've\": \"we have\",\n","\"weren't\": \"were not\",\"what'll\": \"what will\",\"what'll've\": \"what will have\",\"what're\": \"what are\",\n","\"what've\": \"what have\",\"when've\": \"when have\",\"where'd\": \"where did\",\n","\"where've\": \"where have\",\"who'll\": \"who will\",\"who'll've\": \"who will have\",\"who've\": \"who have\",\n","\"why've\": \"why have\",\"will've\": \"will have\",\"won't\": \"will not\",\"won't've\": \"will not have\",\n","\"would've\": \"would have\",\"wouldn't\": \"would not\",\"wouldn't've\": \"would not have\",\"y'all\": \"you all\",\n","\"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","\"you'd\": \"you would\",\"you'd've\": \"you would have\",\"you'll\": \"you will\",\"you'll've\": \"you will have\",\n","\"you're\": \"you are\",\"you've\": \"you have\"}\n","\n","# Save dict\n","pickle.dump(contractions_dict, open(f\"{PATH}utils/contractions_dict.p\", \"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ufOGtIN-AKwe"},"source":["# Init NLP\n","nlp = spacy.load(\"en_core_web_sm\",disable=[\"ner\",\"parser\"])\n","nlp.max_length = 5000000\n","\n","# Preprocess tweets\n","data[\"full_text\"]  = data[\"full_text\"].apply(lambda x: preprocessing(x))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YmZTaWl8TkIw"},"source":["# Save preprocessed data\n","data.to_csv(f\"{PATH}w2d_processed.csv\", index= False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGvZ3xEMEw5U"},"source":["## Word2Vec\n","\n","This part of the notebook is focused on word2vector embedding. First we construct the model vocabulary. Then we represent each document in embedding vector form. \n","\n","In query time we represent the query following the same logic applied to the document and we compute the cosine similarity between each document query term. Finally we return top N most similar documents with respect the query."]},{"cell_type":"code","metadata":{"id":"dLIgtY6-Euc0"},"source":["# Create vocabulary\n","vocabulary = []\n","for tweet in data[\"full_text\"]:\n","    terms = tweet.split()\n","    vocabulary.append(terms)\n","    \n","w2v_model = Word2Vec(vocabulary,size=100, min_count=1,window=2, sg=1,workers=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIkeAHjsUFPm"},"source":["# Save the model\n","w2v_model.save(f\"{PATH}w2v_model.kvmodel\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zD2rrqH7Enmm"},"source":["def embedding_w2v(doc_tokens):\n","    \"\"\"\n","    Returns vector representation of a string\n","    \"\"\"\n","    embeddings = []\n","    if len(doc_tokens)<1:\n","        return np.zeros(100)\n","    else:\n","        for t in doc_tokens:\n","            if t in w2v_model.wv.vocab:\n","                embeddings.append(w2v_model.wv.word_vec(t))\n","            else:\n","                embeddings.append(np.random.rand(100))\n","    \n","    return np.mean(embeddings, axis = 0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qo-ykghn8vxx"},"source":["def w2v_collection(data):\n","    \"\"\"\n","    Given a collection of documents returns the pair id:vector where the vector is\n","    the embedding representation of the doc.\n","    \"\"\"\n","    id_doc2v = {}\n","    for id, text in zip(data[\"id\"].values, data[\"full_text\"]):\n","        id_doc2v[id] = embedding_w2v(text)\n","\n","    return id_doc2v"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2ljlSY8lVp1"},"source":["def rank(query, id_doc2vec):\n","    \"\"\"\n","    Given a query preprocesses it, embeds it and return ordered dictionary of id:similarity_score\n","    pair.\n","    \"\"\"\n","    # Pre-process query\n","    query = preprocessing(query)\n","\n","    # Query vector\n","    q_vector = embedding_w2v(query.split())\n","\n","    #Doc query similarity\n","    doc_query_sim = {k: cosine_similarity(np.array(v).reshape(1,-1),np.array(q_vector).reshape(1,-1)) for k,v in id_doc2vec.items()}\n","\n","    # Sort\n","    doc_query_sim = {k: v for k, v in sorted(doc_query_sim.items(), key=lambda item: item[1], reverse = True)}\n","    \n","    return doc_query_sim"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Lysp4YJa4ac","executionInfo":{"status":"ok","timestamp":1607356062356,"user_tz":-60,"elapsed":1153,"user":{"displayName":"GABRIEL GRAELLS","photoUrl":"","userId":"06318594296163771906"}}},"source":["def parser_tweet_results(doc):\n","  \"\"\"\n","Given a Pandas dataframe row formates the information por display\n","Arguments:\n","  docs -- pandas dataframe with unique row with tweet info.\n","Returns:\n","  tweet -- text tweet - str\n","  authors -- user name of tweet - str\n","  date -- of publication -- str\n","  retweets -- count of retweets - str\n","  favorites -- count of favourites - str\n","  \"\"\"\n","  # Tweet\n","  tweet = str(doc[\"full_text\"].values)\n","  tweet = tweet.replace(\"'\",\"\")\n","  tweet = tweet.replace(\"[\",\"\")\n","  tweet = tweet.replace(\"]\",\"\")\n","\n","  # Author\n","  author = str(doc[\"user.name\"].values)\n","  author = author.replace(\"[\",\"\")\n","  author = author.replace(\"]\",\"\")\n","\n","  # Date\n","  date = str(doc[\"created_at\"].values)\n","  date = date.replace(\"[\",\"\")\n","  date = date.replace(\"]\",\"\")\n","  date = date.replace(\"'\",\"\")\n","\n","  # Retweets\n","  retweets = str(doc[\"retweet_count\"].values)\n","  retweets = retweets.replace(\"[\",\"\")\n","  retweets = retweets.replace(\"]\",\"\")\n","\n","  # Favorites\n","  favorites = str(doc[\"favorite_count\"].values)\n","  favorites = favorites.replace(\"[\",\"\")\n","  favorites = favorites.replace(\"]\",\"\")\n","\n","  # URL\n","  id = str(doc[\"id\"].values)\n","  url = f\"https://twitter.com/twitter/statuses/{id}\"\n","\n","  #Hashtags\n","  hashtags = str(doc[\"entities.hashtags\t\"].values)\n","  \n","  return tweet, date, author, retweets, favorites, url, hashtags"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"8SnK6ukGZy4X"},"source":["def search(id_doc2vector, topn= 20):\n","    \"\"\"\n","    Search for tweets inputing a query and see displayed results.\n","    Arguments:\n","        id_doc2vector -- dic containing id:vec2doc pair - dic\n","        topn -- default: 20 - Top N result to display - int.\n","\n","    \"\"\"\n","    print(\"######################################################\")\n","    print(\"Insert query:\")\n","    query = input()\n","    print(\"######################################################\\n\")\n","\n","    # Get ranked docs\n","    doc_query_sim = rank(query, id_doc2vector)\n","    ids = list(doc_query_sim.keys())[:topn]\n","\n","    for index, id in enumerate(ids):\n","        doc = data_Final[data_Final[\"id\"] == id]\n","        tweet, date, author, retweets, favorites, url, hashtags = parser_tweet_results(doc)\n","    \n","        print(\"______________________________________________________\")\n","        print(f\"Tweet {index}\")\n","        print(f\"\\t·Author: {author}\")\n","        print(f\"\\t·Date: {date}\")\n","        print(f\"\\t·Tweet: {tweet}\")\n","        print(f\"\\t·Retweets: {retweets}\")\n","        print(f\"\\t·Favorites: {favorites}\")\n","        print(f\"\\t·Hashtags: {hashtags}\")\n","        print(f\"\\t·URL: {url}\")\n","        print(\"______________________________________________________\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T7l08f4-Y7mv"},"source":["# Vector representation id:vector\n","id_word2vector = w2v_collection(data)\n","\n","# Save preprocessed data\n","pickle.dump(id_word2vector, open(f\"{PATH}utils/id_word2vector.p\", \"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8yhTekclaav","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607287150598,"user_tz":-60,"elapsed":7885,"user":{"displayName":"GABRIEL GRAELLS","photoUrl":"","userId":"06318594296163771906"}},"outputId":"62e91c18-1032-4c32-f76c-afc50877019e"},"source":["search(id_doc2vector)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["######################################################\n","Insert query:\n","joe Binde\n","######################################################\n","\n","______________________________________________________\n","Tweet 0\n","\t·Author: 'Bloomberg Politics'\n","\t·Date: 2020-10-27\n","\t·Tweet: U.S. backs Taiwan missile sale with China tensions soaring https://t.co/up2ZouDsj4\n","\t·Retweets: 3\n","\t·Favorites: 9\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 1\n","\t·Author: 'HuffPost Politics'\n","\t·Date: 2020-11-04\n","\t·Tweet: “He hasn’t won these states. Nobody is saying he won the states. The states haven’t said he’s won,\" Wallace said. https://t.co/hAuus2BqMK\n","\t·Retweets: 42\n","\t·Favorites: 201\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 2\n","\t·Author: 'Bloomberg Politics'\n","\t·Date: 2020-11-10\n","\t·Tweet: \"For now its still masks and social distancing in the fight against the virus https://t.co/35YRo00obf\"\n","\t·Retweets: 3\n","\t·Favorites: 1\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 3\n","\t·Author: 'Donald J. Trump'\n","\t·Date: 2020-11-02\n","\t·Tweet: Biden will RAISE YOUR TAXES (Biggest increase ever!).\n","\t·Retweets: 22207\n","\t·Favorites: 134204\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 4\n","\t·Author: 'Bloomberg Politics'\n","\t·Date: 2020-11-07\n","\t·Tweet: U.S. Covid hospitalizations soar as new cases top 100,000 a day https://t.co/z0B6jqIJL7\n","\t·Retweets: 3\n","\t·Favorites: 12\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 5\n","\t·Author: 'HuffPost Politics'\n","\t·Date: 2020-11-10\n","\t·Tweet: If a vaccine for COVID-19 does indeed pan out, analysts say it’s a “game changer” and just what the market had been waiting for. https://t.co/HgtTZsQgPc\n","\t·Retweets: 6\n","\t·Favorites: 17\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 6\n","\t·Author: 'Guardian US'\n","\t·Date: 2020-11-02\n","\t·Tweet: Lone Star turn: Kamala Harris campaigns in Texas in bid to flip state https://t.co/McEi6L3z1M\n","\t·Retweets: 2\n","\t·Favorites: 4\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 7\n","\t·Author: 'Guardian US'\n","\t·Date: 2020-11-04\n","\t·Tweet: \"Rafael Nadal shakes off rust to beat López and join ATPs 1,000 club https://t.co/CyT0Kc4qlj\"\n","\t·Retweets: 0\n","\t·Favorites: 4\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 8\n","\t·Author: 'The New York Times'\n","\t·Date: 2020-11-08\n","\t·Tweet: “This is a significant, historic moment for America, for women in America, and for Black Americans and Indian Americans,” Fox News host Dana Perino said on Saturday about the ascendancy of Vice President-elect Kamala Harris. “It’s a big deal.”\\nhttps://t.co/dl0XPX1UoS\n","\t·Retweets: 175\n","\t·Favorites: 2589\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 9\n","\t·Author: 'Guardian US'\n","\t·Date: 2020-11-10\n","\t·Tweet: \"USA plan to educate with anti-racism protest before Wales game, says Adams https://t.co/Q9uQ9ohbj6\"\n","\t·Retweets: 1\n","\t·Favorites: 2\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 10\n","\t·Author: 'Guardian US'\n","\t·Date: 2020-11-06\n","\t·Tweet: A dysfunctional America helps China – but hurts Australia and our region | Natasha Kassam https://t.co/SXhnNbNHiY\n","\t·Retweets: 1\n","\t·Favorites: 7\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 11\n","\t·Author: 'Bloomberg Politics'\n","\t·Date: 2020-10-28\n","\t·Tweet: Saudi Arabia plans to end \"kafala\" labor system, report says https://t.co/44c2YQuIk7\n","\t·Retweets: 3\n","\t·Favorites: 7\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 12\n","\t·Author: 'Bloomberg Politics'\n","\t·Date: 2020-10-28\n","\t·Tweet: A Covid-19 vaccine isn’t likely to be available in the U.S. until at least January, Fauci says https://t.co/tu0Toqq3Q0\n","\t·Retweets: 12\n","\t·Favorites: 21\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 13\n","\t·Author: 'The Washington Post'\n","\t·Date: 2020-10-27\n","\t·Tweet: Delta, United and Alaska Airlines have banned more than 900 passengers for not wearing masks https://t.co/2jy9qdgkzP\n","\t·Retweets: 96\n","\t·Favorites: 858\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 14\n","\t·Author: 'The Washington Post'\n","\t·Date: 2020-11-02\n","\t·Tweet: Kamala Harris could be quietly on the brink of a historic leap https://t.co/DB6PZnN8og\n","\t·Retweets: 150\n","\t·Favorites: 1854\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 15\n","\t·Author: 'The Washington Post'\n","\t·Date: 2020-11-04\n","\t·Tweet: Analysis: The U.S. just left the Paris climate accord, even as the presidential race is undecided https://t.co/nKAmh3uRfE\n","\t·Retweets: 90\n","\t·Favorites: 259\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 16\n","\t·Author: 'Guardian US'\n","\t·Date: 2020-11-05\n","\t·Tweet: Formula One confirm Saudi Arabia 2021 race in face of human rights criticism https://t.co/5eJ8VISF32\n","\t·Retweets: 0\n","\t·Favorites: 3\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 17\n","\t·Author: 'Donald J. Trump'\n","\t·Date: 2020-11-11\n","\t·Tweet: Thanks Dan. Big win for us in Texas! https://t.co/MqNSOf6AWP\n","\t·Retweets: 29974\n","\t·Favorites: 166517\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 18\n","\t·Author: 'HuffPost Politics'\n","\t·Date: 2020-10-27\n","\t·Tweet: The same brown-haired woman appears in political attack ads in Maine, Kansas and Iowa. https://t.co/WHR8XyUIkc\n","\t·Retweets: 172\n","\t·Favorites: 276\n","______________________________________________________\n","\n","______________________________________________________\n","Tweet 19\n","\t·Author: 'The Washington Post'\n","\t·Date: 2020-11-08\n","\t·Tweet: Mexico is poised to legalize marijuana, but advocates don’t like the details https://t.co/O6N7f7EtmR\n","\t·Retweets: 64\n","\t·Favorites: 346\n","______________________________________________________\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7fPna4jlK9ZW"},"source":[""],"execution_count":null,"outputs":[]}]}